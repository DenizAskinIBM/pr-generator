# tasks.yaml
# Defines tasks for the Sequential PR Grouping Crew (Consolidated Batch Processing Tool)

# ----- Analysis Phase Tasks (Executed by analysis_agent) -----

initial_analysis:
  description: >
    Analyze all staged and unstaged changes in the git repository located at '{repo_path}'.
    Use the 'repo_analyzer_tool' to get file paths, statuses, basic statistics, and assign a unique 'file_id'.
    Limit analysis using '{max_files}' if provided.
    You MUST NOT use the Tool Calling/Function Calling format for the Final Answer step for THIS task. Just return the raw JSON string from the observation.
  expected_output: >
    A JSON string serialization of the RepositoryAnalysis object.
  agent: analysis_agent

calculate_global_metrics:
  description: >
    Calculate objective repository metrics based on the RepositoryAnalysis JSON from 'initial_analysis'.
    Use the 'repo_metrics_tool'.
  expected_output: >
    A JSON string serialization of the RepositoryMetrics object.
  agent: analysis_agent

analyze_global_patterns:
  description: >
    Analyze file changes from 'initial_analysis' to identify naming patterns and similarities globally.
    Use the 'pattern_analyzer_tool'.
  expected_output: >
    A JSON string serialization of the PatternAnalysisResult object.
  agent: analysis_agent

select_grouping_strategy:
  description: >
    Based on global analysis results (RepositoryAnalysis, RepositoryMetrics, PatternAnalysisResult JSONs),
    select the most appropriate high-level grouping strategy. Use the 'grouping_strategy_selector_tool'.
  expected_output: >
    A JSON string serialization of the GroupingStrategyDecision object.
  agent: analysis_agent

split_into_batches:
  description: >
    Split the changed files identified in the 'initial_analysis' context into manageable batches.
    1. Extract the RepositoryAnalysis JSON string from the 'initial_analysis' context.
    2. Use the 'batch_splitter_tool'. Pass the extracted string as the 'repository_analysis_json' argument.
       Use '{max_batch_size}' as the 'target_batch_size' argument.
    3. Your final answer MUST be the raw JSON string returned directly by the 'batch_splitter_tool' in the Observation step.
       Do not return the input you used for the tool. Do not add extra formatting or explanations.
  expected_output: >
    A JSON string serialization of the BatchSplitterOutput object, containing 'batches' (a list of lists of file paths), 'strategy_used', and 'notes'.
    Example format: {"batches": [["path/to/file1.py", "path/to/file2.py"], ["path/to/file3.js"]], "strategy_used": "Adaptive complexity...", "notes": "..."}
  agent: analysis_agent

# ----- Consolidated Batch Processing Task (Executed by batch_processor_agent) -----
process_batches_and_generate_results: # Renamed task ID
  description: >
    **CRITICAL BATCH PROCESSING:** Process all file batches generated previously using the dedicated 'Batch Processor Tool'.
    **STEPS:**
    1. **Gather Context JSONs:**
       a. Access the raw output JSON string from the 'split_into_batches' task context. Clean it (remove ```json markers, surrounding text). This is the input for 'batch_splitter_output_json'.
       b. Access the raw output JSON string from the 'select_grouping_strategy' task context. Clean it. This is the input for 'grouping_strategy_decision_json'.
       c. Access the raw output JSON string from the 'initial_analysis' task context. Clean it. This is the input for 'repository_analysis_json'.
       d. Access the raw output JSON string from the 'analyze_global_patterns' task context. Clean it. This is the input for 'pattern_analysis_json' (pass null if not available or irrelevant).
    2. **Verify Inputs:** Ensure all required JSON strings (a, b, c) look like valid JSON objects.
    3. **Call Tool:** Use the 'Batch Processor Tool' exactly once. Provide the cleaned JSON strings from Step 1 as the values for the corresponding arguments ('batch_splitter_output_json', 'grouping_strategy_decision_json', 'repository_analysis_json', 'pattern_analysis_json').
    4. **Final Answer:** Your final answer MUST be the raw JSON array string returned directly by the 'Batch Processor Tool' in the Observation step. Do not add explanations or summaries.
  expected_output: >
    A single, clean JSON array string, where each element is a JSON object representing the PRGroupingStrategy produced by the tool for one batch.
    Example: '[{"strategy_type": "mixed", "groups": [...], "explanation": "Batch 0 result", ...}, {"strategy_type": "mixed", "groups": [...], "explanation": "Batch 1 result", ...}]'
  agent: batch_processor_agent # Agent assigned the BatchProcessorTool

# ----- Merging and Finalization Tasks (Executed by merger_refiner_agent) -----
merge_batch_results:
  description: >
    **CRITICAL MERGING TASK:** Merge the list of batch results into a single PRGroupingStrategy.
    1. Access the raw output string from the 'process_batches_and_generate_results' task. This is the **JSON array string** containing PRGroupingStrategy results for each batch. **DO NOT PARSE THIS STRING YOURSELF.**
    2. Access the raw output string from the 'initial_analysis' task (the full RepositoryAnalysis JSON string).
    3. Clean both strings if necessary (remove ```json markers, surrounding text). Validate they look like JSON.
    4. Use the 'Group Merging Tool'. Provide the cleaned **JSON array string** from Step 1 as 'batch_grouping_results_json' and the cleaned RepositoryAnalysis string from Step 2 as 'original_repository_analysis_json'.
  expected_output: >
    A JSON string serialization of the single, merged PRGroupingStrategy object. This object must be structurally valid.
  agent: merger_refiner_agent

# --- NEW TASK ---
refine_group_names:
  description: >
    **CRITICAL NAMING TASK:** Refine the titles of the merged PR groups using LLM reasoning.
    1. Access the merged PRGroupingStrategy JSON string from the 'merge_batch_results' context. Clean it if necessary.
    2. Parse this JSON string into its object structure.
    3. For **each group** within the 'groups' list:
       a. Examine the list of file paths in the group's 'files' field.
       b. Consider the existing 'title' and 'rationale' for context.
       c. Generate a **concise, descriptive, and unique** title that accurately reflects the primary purpose or theme of the changes in the file list. Use conventional commit message prefixes like 'feat:', 'fix:', 'refactor:', 'chore:', 'docs:', 'style:', 'test:'. Avoid generic titles like 'Update files' or reusing the exact same title for multiple groups if the changes differ.
       d. **Replace** the existing 'title' field of the group with the newly generated title.
       e. (Optional but Recommended) Update the 'rationale' field to briefly explain the *new* title, and regenerate the 'suggested_branch_name' and 'suggested_pr_description' based on the new title using similar logic as the grouping tools. If you update these, ensure the structure remains valid.
    4. After iterating through and updating *all* groups, re-serialize the *entire modified* PRGroupingStrategy object back into a single, clean JSON string.
    5. Your final answer **MUST** be only this resulting JSON string.
  expected_output: >
    A JSON string serialization of the PRGroupingStrategy object, identical in structure to the input from 'merge_batch_results', but with the 'title' (and potentially rationale/branch/description) fields updated for each group based on LLM analysis of the file list.
  agent: merger_refiner_agent # Reusing this agent

final_validation:
  description: >
    Perform a final validation on the PR groups result from the **'refine_group_names'** task (which now contains LLM-refined titles).
    Use the 'group_validator_tool'. Set 'is_final_validation' to 'true'.
    Extract the PRGroupingStrategy JSON string from the **'refine_group_names'** context, clean it, and pass it verbatim as 'pr_grouping_strategy_json'.
  expected_output: >
    A JSON string serialization of the final PRValidationResult object.
  agent: merger_refiner_agent

final_refinement:
  description: >
    **CRITICAL FINAL REFINEMENT TASK:** Refine the merged and name-refined groups based on validation results and ensure all files are included.
    1. Access the PRGroupingStrategy JSON string from **'refine_group_names'**.
    2. Access the PRValidationResult JSON string from 'final_validation'.
    3. Access the full RepositoryAnalysis JSON string from 'initial_analysis'.
    4. Extract these *exact* strings from the context, cleaning any potential ```json markers or surrounding text.
    5. Use the 'group_refiner_tool', providing the cleaned strings as 'pr_grouping_strategy_json', 'pr_validation_result_json', and 'original_repository_analysis_json'. Ensure 'original_repository_analysis_json' is provided for the final completeness check. This tool will primarily fix structural issues (duplicates, missing files); it should *not* override the LLM-generated names unless fixing a structural problem requires it.
  expected_output: >
    A JSON string serialization of the FINAL, polished PRGroupingStrategy object ready for presentation. This object must be structurally valid.
  agent: merger_refiner_agent